{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Simple-2d-gaussian-acquisition-function---update-using-MH\" data-toc-modified-id=\"Simple-2d-gaussian-acquisition-function---update-using-MH-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Simple 2d gaussian acquisition function - update using MH</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generalised model set up that allows passing of arbitrary model for fitting, \n",
    "# hyperparameters can specified as values = [_v1,_v2,...,_vn] for discrete and bounds = [_lower,_upper] for continuous\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------\n",
    "# Bayesian Optimisation Code\n",
    "# --------------------------\n",
    "\n",
    "from scipy.stats import norm\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, Matern,RBF\n",
    "from scipy.optimize import minimize\n",
    "from pyDOE import *\n",
    "\n",
    "# -----------------------------------------\n",
    "# --- Class for a continuous hyperparameter\n",
    "# -----------------------------------------\n",
    "    \n",
    "# --- Define a hyperparameter class that contains all the required specs of the hyperparameter\n",
    "class hyperparam(object):\n",
    "    \n",
    "    def __init__(self,list_in):\n",
    "        \n",
    "        # Initiate with 2 types of variable. We either specify bounds\n",
    "        # for continuous variable or values for discrete. Note that for\n",
    "        # now the values must be integers and be a list of consecutive\n",
    "        #Â integers.\n",
    "        if len(list_in) == 2:\n",
    "            self.bounds = list_in\n",
    "            self.kind = 'continuous'\n",
    "        elif len(list_in) > 2:\n",
    "            self.bounds = [list_in[0],list_in[-1]]\n",
    "            self.kind = 'discrete'\n",
    "            self.vals = list_in\n",
    "        \n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "class iteration(object):\n",
    "    \n",
    "    def __init__(self,pars):\n",
    "        \n",
    "        \n",
    "#         # --- Sample data\n",
    "        self.Xt = pars.Xt\n",
    "        self.Yt = pars.Yt\n",
    "       \n",
    "        # Obtain next sampling point from the acquisition function (expected_improvement)\n",
    "        X_next = self.propose_location(pars)\n",
    "        # Convert to int where necessary\n",
    "        \n",
    "        # We need to recreate a dictionary with the keys given by the hyperparameter name before pasing into our\n",
    "        # ML model\n",
    "        self.X_nextdict = {}\n",
    "        for i,hps1 in enumerate(sorted(pars.Xtdict.keys())):\n",
    "            if pars.hps[hps1].kind == 'discrete':\n",
    "                X_next[i] = int(X_next[i])\n",
    "                self.X_nextdict[hps1] = X_next[i]\n",
    "            else:\n",
    "                self.X_nextdict[hps1] = X_next[i]\n",
    "        \n",
    "        #X_next = np.array(X_next,ndmin=(2)).reshape(1,-1)\n",
    "        Y_next = pars.objF(self.X_nextdict)\n",
    "        \n",
    "        # Add the new sample point to the existing for the next iteration\n",
    "        self.Xt = np.vstack((self.Xt, X_next.reshape(1,-1)[0]))\n",
    "        self.Yt = np.concatenate((self.Yt, Y_next))\n",
    "    \n",
    "    # Sampling function to find the next values for the hyperparameters\n",
    "    def propose_location(self,pars):\n",
    "        \n",
    "        # Proposes the next sampling point by optimizing the acquisition function. Args: acquisition: Acquisition function. X_sample: Sample locations (n x d). Y_sample: Sample values (n x 1). gpr: A GaussianProcessRegressor fitted to samples. Returns: Location of the acquisition function maximum. '''\n",
    "        self.N_hps = pars.Xt.shape[1]\n",
    "        min_val = 1\n",
    "        min_x = None\n",
    "\n",
    "        self.gpr = pars.gpr\n",
    "        self.Xt = pars.Xt\n",
    "    \n",
    "\n",
    "\n",
    "        # Find the best optimum by starting from n_restart different random points.\n",
    "        Xs = lhs(self.N_hps, samples=pars.n_restarts, criterion='centermaximin')\n",
    "        for i,hp in enumerate(sorted(pars.hps.keys())):\n",
    "            Xs[:,i] = Xs[:,i]*(pars.hps[hp].bounds[1]-pars.hps[hp].bounds[0])+pars.hps[hp].bounds[0]\n",
    "        \n",
    "            # Convert int values to integers\n",
    "            if pars.hps[hp].kind == 'discrete':\n",
    "                Xs[:,i] = Xs[:,i].astype(int)\n",
    "        \n",
    "        # Find the maximum in the acquisition function\n",
    "        if pars.optim_rout == 'minimize':\n",
    "            for x0 in Xs:\n",
    "                res = minimize(self.min_obj, x0=x0, bounds=pars.bounds, method=pars.method) \n",
    "                # Find the best optimum across all initiations\n",
    "                if res.fun < min_val:\n",
    "                    min_val = res.fun[0]\n",
    "                    min_x = res.x   \n",
    "                    \n",
    "        elif pars.optim_rout == 'MCMC-MH':\n",
    "            for x0 in Xs:\n",
    "                res_x,res_f = self.MetroHastings(x0,[0.1]*self.N_hps,10000,tuple(pars.bounds))\n",
    "                if res_f < min_val:\n",
    "                    min_val = res_f\n",
    "                    min_x = res_x\n",
    "                    \n",
    "        elif pars.optim_rout == 'MCMC-discrete':\n",
    "            for x0 in Xs:\n",
    "                res_x,res_f = self.discrete_MCMC(x0,pars.x_dict,10000)\n",
    "                if res_f < min_val:\n",
    "                    min_val = res_f\n",
    "                    min_x = res_x\n",
    "\n",
    "        return min_x.reshape(-1, 1)\n",
    "    \n",
    "    def min_obj(self,X):\n",
    "    # Minimization objective is the negative acquisition function\n",
    "        return -self.expected_improvement(X.reshape(-1, self.N_hps))\n",
    "    \n",
    "    def max_obj(self,X):\n",
    "    # Minimization objective is the negative acquisition function\n",
    "        return self.expected_improvement(X.reshape(-1, self.N_hps))\n",
    "        \n",
    "    # Acquisition function - here we use expected improvement\n",
    "    def expected_improvement(self,X):\n",
    "        \n",
    "        # --- Computes the EI at points X based on existing samples X_sample and Y_sample using a Gaussian process \n",
    "        # surrogate model. \n",
    "        # X: Points at which EI shall be computed (m x d). \n",
    "        # X_sample: Sample locations (n x d). \n",
    "        # Y_sample: Sample values (n x 1). \n",
    "        # gpr: A GaussianProcessRegressor fitted to samples. \n",
    "        # xi: Exploitation-exploration trade-off parameter. \n",
    "        #.   - xi ~ O(0) => exploitation\n",
    "        #.   - xi ~ O(1) => exploration\n",
    "        # Returns: Expected improvements at points X.\n",
    "\n",
    "        # Evaluate the Gaussian Process at a test location X to get the mean and std\n",
    "        mu, sigma = self.gpr.predict(X, return_std=True)\n",
    "        # Evaluate the Gaussian Process at the sampled points - this gets the mean values without the noise\n",
    "        mu_sample = self.gpr.predict(self.Xt)\n",
    "\n",
    "        \n",
    "        sigma = sigma.reshape(-1, 1)#self.Xt.shape[1])\n",
    "\n",
    "        # Needed for noise-based model,\n",
    "        # otherwise use np.max(Y_sample).\n",
    "        # See also section 2.4 in [...]\n",
    "        mu_sample_opt = np.max(mu_sample)\n",
    "\n",
    "        imp = mu - mu_sample_opt\n",
    "        Z = imp / sigma\n",
    "\n",
    "        Ei = (mu-mu_sample_opt) * norm.cdf(mu,loc=mu_sample_opt, scale=sigma) \\\n",
    "            + mu_sample_opt * norm.pdf(mu,loc=mu_sample_opt, scale=sigma)\n",
    "\n",
    "\n",
    "        return Ei\n",
    "    \n",
    "    def MetroHastings(self,x0,sig,Niter,bounds):\n",
    "    \n",
    "        \"Function to perform metropolis Hastings sampling in an MCMC\"\n",
    "\n",
    "        # --- Input ---\n",
    "        # x0: initial guess for random walk - list of continuous variables\n",
    "        # sig is the uncertainty in the MH sampling algorithm\n",
    "        # Niter is number of iterations to perform\n",
    "        # bounds: list of tuples of length x0, each one being the lower and upper bounds \n",
    "\n",
    "        # --- Output ---\n",
    "        # Modal solution from the MCMC\n",
    "\n",
    "        # Calculate initial guess\n",
    "        acq = np.zeros(Niter)\n",
    "        acq[0] = self.min_obj(x0.reshape(1,-1))\n",
    "\n",
    "        # proposition point\n",
    "        xp = np.zeros((len(x0),Niter))\n",
    "        xp[:,0] = x0\n",
    "\n",
    "        for iiter in range(1,Niter):\n",
    "\n",
    "            # Propose new data point to try using MH\n",
    "            for i in range(len(x0)):\n",
    "\n",
    "                # iterate until we get a point in the correct interval\n",
    "                if x0[i]<bounds[i][0]:\n",
    "                    loc0 = bounds[i][0]\n",
    "                elif x0[i]>bounds[i][1]:\n",
    "                    loc0 = bounds[i][1]\n",
    "                else:\n",
    "                    loc0 = x0[i]\n",
    "\n",
    "                Pnext = np.random.normal(loc=loc0,scale=sig[i])\n",
    "                while (Pnext < bounds[i][0]) | (Pnext >= bounds[i][1]):\n",
    "                    Pnext = np.random.normal(loc=loc0,scale=sig[i])\n",
    "\n",
    "                # Then choose the first point that is    \n",
    "                xp[i,iiter] = Pnext\n",
    "\n",
    "            # Test value at this point\n",
    "            acq[iiter] = self.min_obj(xp[:,iiter].reshape(1,-1))\n",
    "\n",
    "            # Check if proposed point is better\n",
    "            if acq[iiter] > acq[iiter-1]:\n",
    "                x0 = xp[:,iiter].copy()\n",
    "\n",
    "            else:\n",
    "                p0 = [acq[iiter-1]/(acq[iiter]+acq[iiter-1]),acq[iiter]/(acq[iiter]+acq[iiter-1])]\n",
    "                nextP = np.random.choice([0,1],p=p0)\n",
    "\n",
    "                if nextP == 1:\n",
    "                    x0 = xp[:,iiter].copy()\n",
    "                else:\n",
    "                    x0 = xp[:,iiter-1].copy()\n",
    "                    \n",
    "            \n",
    "        # Now get optimal solution by fitting a histogram to the data - ignore first 10% of samples\n",
    "        optim_x = np.zeros((1,len(x0)))   \n",
    "        for i in range(optim_x.shape[1]):\n",
    "            optim_x[0,i] = kernel_density_estimation(xp[i,int(0.1*Niter):],Niter)\n",
    "\n",
    "        return optim_x,self.min_obj(optim_x.reshape(1,-1))\n",
    "\n",
    "    def kernel_density_estimation(self,xpi,Niter):\n",
    "\n",
    "        \" Function to find peak in a kernel density \"\n",
    "\n",
    "        # We initially fudge this to get it working! \n",
    "        # So we fit a histogram and then find the middle of the tallest bar\n",
    "\n",
    "        # Fit a histogram\n",
    "        data = xpi.copy()\n",
    "        data.sort()\n",
    "        hist, bin_edges = np.histogram(data, density=True,bins=max(10,30))\n",
    "\n",
    "        # Return the middle of the largest bin\n",
    "        n = np.argmax(hist)\n",
    "        return np.mean(bin_edges[n:n+2])\n",
    "    \n",
    "    def discrete_MCMC(self,x0,x_dict,Niter):\n",
    "\n",
    "        \"Function to perform fully discrete metropolis Hastings sampled MCMC\"\n",
    "\n",
    "        # --- Input ---\n",
    "        # x0: starting guess\n",
    "        # Niter is number of iterations to perform\n",
    "        # bounds: dictionary of values for each variable with key equal to the position in the array \n",
    "\n",
    "        # --- Output ---\n",
    "        # Modal solution from the MCMC\n",
    "\n",
    "        # Calculate initial guess\n",
    "        acq = np.zeros(Niter)\n",
    "        acq[0] = acquisition_function(np.array(x0).reshape(1,-1))\n",
    "\n",
    "        # proposition point\n",
    "        xp = np.zeros((len(x0),Niter))\n",
    "        xp[:,0] = x0\n",
    "\n",
    "        # count frequency of each value appearing\n",
    "        N_dict = {}\n",
    "        for k1 in x_dict.keys():\n",
    "            N_dict[k1] = np.zeros(len(x_dict[k1]))\n",
    "\n",
    "        for iiter in range(1,Niter):\n",
    "\n",
    "            # Choose a location to swap\n",
    "            i_choice = np.random.choice(range(len(x0)))\n",
    "\n",
    "            # Set xp to be x0\n",
    "            xp[:,iiter] = x0.copy()\n",
    "            # choose a new value for the i_choice-th entry\n",
    "            xp[i_choice,iiter] = np.random.choice(x_dict[i_choice])\n",
    "\n",
    "            # Test value at this point\n",
    "            acq[iiter] = acquisition_function(xp[:,iiter].reshape(1,-1))\n",
    "\n",
    "            # Check if proposed point is better\n",
    "            if acq[iiter] > acq[iiter-1]:\n",
    "                x0 = xp[:,iiter].copy()\n",
    "\n",
    "            else:\n",
    "                p0 = [acq[iiter-1]/(acq[iiter]+acq[iiter-1]),acq[iiter]/(acq[iiter]+acq[iiter-1])]\n",
    "                nextP = np.random.choice([0,1],p=p0)\n",
    "                if nextP == 1:\n",
    "                    x0 = xp[:,iiter].copy()\n",
    "                else:\n",
    "                    x0 = xp[:,iiter-1].copy()\n",
    "\n",
    "            # accumulate the counts - when iiter excedes a 10th of Niter\n",
    "            if iiter > 0.1*Niter:\n",
    "                for aci in range(len(x0)):\n",
    "                    N_dict[aci][x_dict[aci].index(x0[aci])] += 1\n",
    "\n",
    "        # Now get optimal solution by fitting a histogram to the data - already ignored first 10% of samples\n",
    "        optim_x = np.zeros((1,len(x0)))   \n",
    "        for i in range(len(x0)):\n",
    "            optim_x[0,i] = x_dict[i][np.argmax(N_dict[i])]\n",
    "\n",
    "        return optim_x,acquisition_function(optim_x[0,:].reshape(1,-1))\n",
    "    \n",
    "    \n",
    "    \n",
    "class BayesianOptimisation(object):\n",
    "    \n",
    "    def __init__(self,**kwargs):\n",
    "        \n",
    "        # Get hyperparameter info and convert to hyperparameter class\n",
    "        self.hps = {}\n",
    "        for hp in kwargs['hps'].keys():\n",
    "            self.hps[hp] = hyperparam(kwargs['hps'][hp])\n",
    "        \n",
    "        # Objective function to minimise\n",
    "        self.MLmodel = kwargs['MLmodel']\n",
    "        \n",
    "            \n",
    "        # Number of hyperparameters\n",
    "        N_hps = len(self.hps.keys())\n",
    "        \n",
    "        # --- Initial sample data\n",
    "        if 'NpI' in kwargs.keys():\n",
    "            self.NpI = kwargs['NpI']\n",
    "        else:\n",
    "            self.NpI = 2**N_hps\n",
    "            \n",
    "        # --- Optimisation routine for the acquisition function\n",
    "        if 'optim_rout' in kwargs.keys():\n",
    "            self.optim_rout = kwargs['optim_rout']\n",
    "            # Now define a new dictionary for use in discrete MCMC optimisation\n",
    "            if self.optim_rout == 'MCMC-discrete':\n",
    "                self.x_dict = {}\n",
    "                for i,hp in enumerate(self.hps.keys()):\n",
    "                    self.x_dict[i] = list(self.hps[hp].vals)\n",
    "        else:\n",
    "            self.optim_rout = 'minimize'\n",
    "        \n",
    "        \n",
    "        # Establish a dictionary for our hyperparameter values that we sample\n",
    "        self.Xtdict = {}\n",
    "        # ...and then an array for the same thing but with each column being\n",
    "        # a different hyperparameter and ordered alphabetically\n",
    "        self.Xt = np.zeros((self.NpI,len(self.hps.keys())))\n",
    "        # We also need to collect together all of the bounds for the optimization routing into one array\n",
    "        self.bounds = np.zeros((2,len(self.hps.keys())))\n",
    "        \n",
    "        # Get some initial samples on the unit interval\n",
    "        Xt = lhs(len(self.hps.keys()), samples=self.NpI, criterion='centermaximin')\n",
    "        \n",
    "        # For each hyper parameter, rescale the unit inverval on the \n",
    "        # appropriate range for that hp and store in a dict\n",
    "        for i,hp in enumerate(sorted(self.hps.keys())):\n",
    "            self.Xtdict[hp] = self.hps[hp].bounds[0]+Xt[:,i]*(self.hps[hp].bounds[1]-self.hps[hp].bounds[0])\n",
    "            # convert these to an int if kind = 'discrete'\n",
    "            \n",
    "            if self.hps[hp].kind == 'discrete':\n",
    "                self.Xtdict[hp] = self.Xtdict[hp].astype(int)\n",
    "            \n",
    "            self.bounds[i,:] = self.hps[hp].bounds\n",
    "\n",
    "            self.Xt[:,i] = self.Xtdict[hp]\n",
    "    \n",
    "\n",
    "        \n",
    "            \n",
    "        # Calculate objective function at the sampled points\n",
    "        self.Yt = self.objF(pars=self.Xtdict,n=self.NpI)\n",
    "\n",
    "        \n",
    "        \n",
    "        # --- Number of iterations\n",
    "        if 'Niter' in kwargs.keys():\n",
    "            self.Niter = kwargs['Niter']\n",
    "        else:\n",
    "            self.Niter = 10*N_hps\n",
    "            \n",
    "        # --- Number of optimisations of the acquisition function\n",
    "        if 'n_restarts' in kwargs.keys():\n",
    "            self.n_restarts = kwargs['n_restarts']\n",
    "        else:\n",
    "            self.n_restarts = 25*N_hps\n",
    "            \n",
    "        # --- Optimisation method used\n",
    "        if 'method' in kwargs.keys():\n",
    "            self.method = kwargs['method']\n",
    "        else:\n",
    "            self.method = 'L-BFGS-B'\n",
    "            \n",
    "        \n",
    "        # --- Define the Gaussian mixture model\n",
    "        if 'kernel' in kwargs.keys():\n",
    "            self.kernel = kwargs['kernel']\n",
    "        else:\n",
    "            self.kernel = RBF()\n",
    "            \n",
    "        if 'noise' in kwargs.keys():\n",
    "            self.noise = kwargs['noise']\n",
    "        else:\n",
    "            self.noise = noise = 0.2\n",
    "            \n",
    "        self.gpr = GaussianProcessRegressor(kernel=self.kernel, alpha=noise**2)\n",
    "        \n",
    "    def optimise(self):\n",
    "        for i in range(self.Niter):\n",
    "            it1 = iteration(self)\n",
    "            self.Xt = it1.Xt\n",
    "            self.Yt = it1.Yt\n",
    "            if i == 0:\n",
    "                print self.Yt\n",
    "            print('current accuracy:',self.Yt[-1])\n",
    "            print('best accuracy:', max(self.Yt))\n",
    "            self.gpr.fit(self.Xt, self.Yt)\n",
    "        return self\n",
    "    \n",
    "    def objF(self,pars,**kwargs):\n",
    "        \n",
    "        # Number of hyperparameter values to try. \n",
    "        n = 1\n",
    "        if 'n' in kwargs.keys():\n",
    "            n = kwargs['n']\n",
    "\n",
    "        # Initiate array to accumate the accuracy of the model\n",
    "        sc = np.zeros(n)\n",
    "        \n",
    "        # Establish the basic ML model\n",
    "        model = self.MLmodel\n",
    "        \n",
    "        for i in range(n):\n",
    "            \n",
    "            # Get dictionary of hyperparameter values to test at the ith iteration\n",
    "            hps_iter = {}\n",
    "            for hp in pars.keys():\n",
    "                if self.hps[hp].kind == 'discrete':\n",
    "                    hps_iter[hp] = int(pars[hp][i])\n",
    "                else:\n",
    "                    hps_iter[hp] = pars[hp][i]\n",
    "                \n",
    "            # Create instance of MLmodel with the hps at this iteration\n",
    "            model.set_params(**hps_iter)\n",
    "        \n",
    "            # Train\n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            \n",
    "            # Score\n",
    "            sc[i] = np.mean(cross_val_score(model, self.X_train, self.y_train, cv=5))\n",
    "            \n",
    "        return sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91806558 0.89053836 0.91134587]\n",
      "('current accuracy:', 0.9113458678303322)\n",
      "('best accuracy:', 0.9180655764049401)\n",
      "('current accuracy:', 0.9181093631573619)\n",
      "('best accuracy:', 0.9181093631573619)\n",
      "('current accuracy:', 0.9233131366963756)\n",
      "('best accuracy:', 0.9233131366963756)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-72-132ac832d170>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0moptim_rout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'MCMC-discrete'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mNpI\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mNiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m ).optimise()\n",
      "\u001b[0;32m<ipython-input-70-8f8b82a2cf03>\u001b[0m in \u001b[0;36moptimise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    403\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptimise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 405\u001b[0;31m             \u001b[0mit1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    406\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    407\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mit1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mYt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-8f8b82a2cf03>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, pars)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m         \u001b[0;31m# Obtain next sampling point from the acquisition function (expected_improvement)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0mX_next\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropose_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m         \u001b[0;31m# Convert to int where necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-8f8b82a2cf03>\u001b[0m in \u001b[0;36mpropose_location\u001b[0;34m(self, pars)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim_rout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'MCMC-discrete'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mx0\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m                 \u001b[0mres_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mres_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiscrete_MCMC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mres_f\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmin_val\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mmin_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-70-8f8b82a2cf03>\u001b[0m in \u001b[0;36mdiscrete_MCMC\u001b[0;34m(self, x0, x_dict, Niter)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;31m# Choose a location to swap\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0mi_choice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0;31m# Set xp to be x0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "X_train = 15*np.random.uniform(size=(100,2))\n",
    "\n",
    "y_train = np.zeros((100,1))\n",
    "for i in range(X_train.shape[0]):\n",
    "    y_train[i] = 1-acquisition_function(X_train[i,:].reshape(1,-1))\n",
    "y_train = y_train+0.1*np.random.uniform(size=(100,1))\n",
    "y_train = y_train.ravel()\n",
    "y_train\n",
    "hps_rf = {\n",
    "    'n_estimators':range(1,10),\n",
    "    'max_depth':range(1,10)\n",
    "}\n",
    "BOout = BayesianOptimisation(\n",
    "    hps=hps_rf,\n",
    "    MLmodel = RandomForestRegressor(random_state= 42),\n",
    "    optim_rout = 'MCMC-discrete',\n",
    "    NpI = 2,\n",
    "    Niter = 5\n",
    ").optimise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = BOout.Xt[np.argmax(BOout.Yt)]\n",
    "RFr = RandomForestRegressor(\n",
    "    n_estimators=int(best_params[0]),\n",
    "    max_depth=int(best_params[1]),\n",
    "    random_state=42\n",
    ").fit(X_train,y_train)\n",
    "np.mean(cross_val_score(RFr, X_train,y_train, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(121)\n",
    "plt.plot(BOout.Xt,'.')\n",
    "plt.subplot(122)\n",
    "plt.plot(BOout.Yt,'.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple 2d gaussian acquisition function - update using MH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquisition_function(z):\n",
    "    x=z[0,0]\n",
    "    y=z[0,1]\n",
    "    return np.exp(-((x-5)/10)**2)*np.exp(-((y-10)/10)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-fe6858a0c031>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-73-dd329c12dea6>\u001b[0m in \u001b[0;36macquisition_function\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "\n",
    "plt.plot(np.linspace(0,1),acquisition_function(np.linspace(0,1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MetroHastings(x0,optim_func,sig,Niter,bounds):\n",
    "    \n",
    "    \"Function to perform metropolis Hastings sampling in an MCMC\"\n",
    "    \n",
    "    # --- Input ---\n",
    "    # x0: initial guess for random walk - list of continuous variables\n",
    "    # sig is the uncertainty in the MH sampling algorithm\n",
    "    # Niter is number of iterations to perform\n",
    "    # bounds: list of tuples of length x0, each one being the lower and upper bounds \n",
    "    \n",
    "    # --- Output ---\n",
    "    # Modal solution from the MCMC\n",
    "    \n",
    "    # Calculate initial guess\n",
    "    acq = np.zeros(Niter)\n",
    "    acq[0] = acquisition_function(x0[0],x0[1])\n",
    "    \n",
    "    # proposition point\n",
    "    xp = np.zeros((len(x0),Niter))\n",
    "    xp[:,0] = x0\n",
    "    \n",
    "    for iiter in range(1,Niter):\n",
    "        \n",
    "        # Propose new data point to try using MH\n",
    "        for i in range(len(x0)):\n",
    "            \n",
    "            # iterate until we get a point in the correct interval\n",
    "            if x0[i]<bounds[i][0]:\n",
    "                loc0 = bounds[i][0]\n",
    "            elif x0[i]>bounds[i][1]:\n",
    "                loc0 = bounds[i][1]\n",
    "            else:\n",
    "                loc0 = x0[i]\n",
    "            \n",
    "            Pnext = np.random.normal(loc=loc0,scale=sig[i])\n",
    "            while (Pnext < bounds[i][0]) | (Pnext >= bounds[i][1]):\n",
    "                Pnext = np.random.normal(loc=loc0,scale=sig[i])\n",
    "                \n",
    "            # Then choose the first point that is    \n",
    "            xp[i,iiter] = Pnext\n",
    "            \n",
    "        # Test value at this point\n",
    "        acq[iiter] = acquisition_function(xp[0,iiter],xp[1,iiter])\n",
    "        \n",
    "        # Check if proposed point is better\n",
    "        if acq[iiter] > acq[iiter-1]:\n",
    "            x0 = xp[:,iiter].copy()\n",
    "        \n",
    "        else:\n",
    "            p0 = [acq[iiter-1]/(acq[iiter]+acq[iiter-1]),acq[iiter]/(acq[iiter]+acq[iiter-1])]\n",
    "            nextP = np.random.choice([0,1],p=p0)\n",
    "            if nextP == 1:\n",
    "                x0 = xp[:,iiter].copy()\n",
    "            else:\n",
    "                x0 = xp[:,iiter-1].copy()\n",
    "  \n",
    "    # Now get optimal solution by fitting a histogram to the data\n",
    "    optim_x = np.zeros((1,len(x0)))   \n",
    "    for i in range(optim_x.shape[1]):\n",
    "        optim_x[0,i] = kernel_density_estimation(xp[i,int(0.1*Niter):],Niter)\n",
    "        \n",
    "    return optim_x,acquisition_function(optim_x[0,0],optim_x[0,1])\n",
    "    \n",
    "def kernel_density_estimation(xpi,Niter):\n",
    "    \n",
    "    \" Function to peak in a kernel density \"\n",
    "    \n",
    "    # We initially fudge this to get it working!\n",
    "    \n",
    "    # Fit a histogram\n",
    "    data = xpi.copy()\n",
    "    data.sort()\n",
    "    hist, bin_edges = np.histogram(data, density=True,bins=max(10,30))\n",
    "    \n",
    "    # Return the largest bin\n",
    "    n = np.argmax(hist)\n",
    "    return np.mean(bin_edges[n:n+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discrete_MCMC(x0,x_dict,Niter):\n",
    "\n",
    "    \"Function to perform fully discrete metropolis Hastings sampled MCMC\"\n",
    "    \n",
    "    # --- Input ---\n",
    "    # x0: starting guess\n",
    "    # Niter is number of iterations to perform\n",
    "    # bounds: dictionary of values for each variable with key equal to the position in the array \n",
    "    \n",
    "    # --- Output ---\n",
    "    # Modal solution from the MCMC\n",
    "    \n",
    "    # Calculate initial guess\n",
    "    acq = np.zeros(Niter)\n",
    "    acq[0] = acquisition_function(np.array(x0).reshape(1,-1))\n",
    "    \n",
    "    # proposition point\n",
    "    xp = np.zeros((len(x0),Niter))\n",
    "    xp[:,0] = x0\n",
    "    \n",
    "    # count frequency of each value appearing\n",
    "    N_dict = {}\n",
    "    for k1 in x_dict.keys():\n",
    "        N_dict[k1] = np.zeros(len(x_dict[k1]))\n",
    "    \n",
    "    for iiter in range(1,Niter):\n",
    "        \n",
    "        # Choose a location to swap\n",
    "        i_choice = np.random.choice(range(len(x0)))\n",
    "            \n",
    "        # Set xp to be x0\n",
    "        xp[:,iiter] = x0.copy()\n",
    "        # choose a new value for the i_choice-th entry\n",
    "        xp[i_choice,iiter] = np.random.choice(x_dict[i_choice])\n",
    "                    \n",
    "        # Test value at this point\n",
    "        acq[iiter] = acquisition_function(xp[:,iiter].reshape(1,-1))\n",
    "        \n",
    "        # Check if proposed point is better\n",
    "        if acq[iiter] > acq[iiter-1]:\n",
    "            x0 = xp[:,iiter].copy()\n",
    "        \n",
    "        else:\n",
    "            p0 = [acq[iiter-1]/(acq[iiter]+acq[iiter-1]),acq[iiter]/(acq[iiter]+acq[iiter-1])]\n",
    "            nextP = np.random.choice([0,1],p=p0)\n",
    "            if nextP == 1:\n",
    "                x0 = xp[:,iiter].copy()\n",
    "            else:\n",
    "                x0 = xp[:,iiter-1].copy()\n",
    "                \n",
    "        # accumulate the counts - when iiter excedes a 10th of Niter\n",
    "        if iiter > 0.1*Niter:\n",
    "            for aci in range(len(x0)):\n",
    "                N_dict[aci][x_dict[aci].index(x0[aci])] += 1\n",
    "  \n",
    "    # Now get optimal solution by fitting a histogram to the data\n",
    "    optim_x = np.zeros((1,len(x0)))   \n",
    "    for i in range(len(x0)):\n",
    "        optim_x[0,i] = x_dict[i][np.argmax(N_dict[i])]\n",
    "        \n",
    "    return optim_x,acquisition_function(optim_x[0,:].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dict = {}\n",
    "x_dict[0] = range(1,11)\n",
    "x_dict[1] = range(1,21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "Niter = 20000\n",
    "guess = np.array([\n",
    "    np.random.choice(x_dict[0]),\n",
    "    np.random.choice(x_dict[1])\n",
    "])\n",
    "optim_x,optim_f = discrete_MCMC(guess,x_dict,Niter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'N_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-b5aec7e4715c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mN_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'N_dict' is not defined"
     ]
    }
   ],
   "source": [
    "N_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5., 9.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9900498337491681"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "acquisition_function() takes exactly 1 argument (2 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-dd26bcff4162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mNiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptim_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptim_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMetroHastings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mNiter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-9bfe9c8e1f58>\u001b[0m in \u001b[0;36mMetroHastings\u001b[0;34m(x0, optim_func, sig, Niter, bounds)\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;31m# Calculate initial guess\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0macq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0macq\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquisition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;31m# proposition point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: acquisition_function() takes exactly 1 argument (2 given)"
     ]
    }
   ],
   "source": [
    "Niter = 10000\n",
    "optim_x,optim_f = MetroHastings([0.1,0.4],acquisition_function,[0.1,0.1],Niter,[(0,1),(0,1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[5., 9.]]), 0.9900498337491681)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_x,optim_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-d90e127578d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnormed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnorm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'xp' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.hist(xp[0],normed=True,bins=max(10,20))\n",
    "\n",
    "mu, std = norm.fit(xp[0])\n",
    "xlin = np.linspace(0,1)\n",
    "plt.plot(xlin,norm.pdf(xlin, mu, std))\n",
    "\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.hist(xp[1],normed=True,bins=max(10,20))\n",
    "\n",
    "mu, std = norm.fit(xp[1])\n",
    "xlin = np.linspace(0,1)\n",
    "plt.plot(xlin,norm.pdf(xlin, mu, std))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48339815, 0.51669011]])"
      ]
     },
     "execution_count": 475,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optim_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "kernel_density_estimation() takes exactly 2 arguments (1 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-476-07e3474e275a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Save the mean - ie highest density of points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0moptim_x\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkernel_density_estimation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: kernel_density_estimation() takes exactly 2 arguments (1 given)"
     ]
    }
   ],
   "source": [
    "optim_x = np.zeros((1,len(x0)))   \n",
    "for i in range(len(optim_x)):\n",
    "    # Fit a normal\n",
    "\n",
    "    # Save the mean - ie highest density of points\n",
    "    optim_x[i] = kernel_density_estimation(xp[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1       , 0.01190927, 0.12435207, ..., 0.22757897, 0.25576384,\n",
       "       0.25381378])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = xp[0].copy()\n",
    "data.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist, bin_edges = np.histogram(data, density=True,bins=int(Niter/100))\n",
    "#hist, bin_edges = np.histogram(data, density=True,bins=bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Niter = 10000\n",
    "Niter/(100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.zeros((1,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Non-ASCII character '\\xc2' in file BayesianHyperparameter3.py on line 23, but no encoding declared; see http://www.python.org/peps/pep-0263.html for details (BayesianHyperparameter3.py, line 23)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"BayesianHyperparameter3.py\"\u001b[0;36m, line \u001b[0;32m23\u001b[0m\n\u001b[0;31m    #Â integers.\u001b[0m\n\u001b[0m     Â          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Non-ASCII character '\\xc2' in file BayesianHyperparameter3.py on line 23, but no encoding declared; see http://www.python.org/peps/pep-0263.html for details\n"
     ]
    }
   ],
   "source": [
    "import BayesianHyperparameter3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
